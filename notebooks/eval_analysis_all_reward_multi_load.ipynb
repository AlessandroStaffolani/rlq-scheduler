{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "from rlq_scheduler.common.config_helper import GlobalConfigHelper\n",
    "from rlq_scheduler.common.plot_utils.stats import get_stats_dataframe, load_agents_data,\\\n",
    "    print_status, get_assignment_history_df\n",
    "from rlq_scheduler.common.object_handler import MinioObjectHandler\n",
    "\n",
    "sns.set(style=\"darkgrid\", font_scale=2)\n",
    "# reference here https://matplotlib.org/3.1.1/tutorials/introductory/customizing.html\n",
    "rc = {\n",
    "    'lines.linewidth': 1,\n",
    "    'lines.markersize': 10,\n",
    "    'axes.titlesize': 18,\n",
    "    'axes.labelsize': 16,\n",
    "    'xtick.labelsize': 16,\n",
    "    'ytick.labelsize': 16,\n",
    "    'legend.fancybox': False,\n",
    "    'figure.titlesize' : 18,\n",
    "    'legend.fontsize': 16,\n",
    "    'legend.title_fontsize': 16\n",
    "}\n",
    "# sns.set_context(\"notebook\", rc=rc)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(processName)-10s | %(message)s\")\n",
    "logger = logging.getLogger()\n",
    "\n",
    "global_config = GlobalConfigHelper(config_path='config/global.yml')\n",
    "global_config.config['object_handler']['default_bucket'] = 'sb1'\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('/jupyter/evaluation-images'):\n",
    "    os.mkdir('/jupyter/evaluation-images')\n",
    "    \n",
    "BASE_PATH = '/jupyter/evaluation-images/multi-load'\n",
    "if not os.path.exists(BASE_PATH):\n",
    "    os.mkdir(BASE_PATH)\n",
    "\n",
    "rew_names = ['waiting-time', 'execution-time', 'execution-cost']\n",
    "for name in rew_names:\n",
    "    path = os.path.join(BASE_PATH, name)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "endpoint = \"10.25.1.120:9000\" # os.getenv('MINIO_ENDPOINT')\n",
    "access_key = os.getenv('MINIO_ACCESSKEY')\n",
    "secret_key = os.getenv('MINIO_SECRETKEY')\n",
    "secure = bool(os.getenv('MINIO_SECURE'))\n",
    "handler = MinioObjectHandler(\n",
    "    endpoint=endpoint,\n",
    "    access_key=access_key,\n",
    "    secret_key=secret_key,\n",
    "    secure=secure,\n",
    "    default_bucket=global_config.object_handler_base_bucket()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_datatable(prop, parent_prop):\n",
    "    data = []\n",
    "    columns = [prop, 't', 'agent', 'seed']\n",
    "    for agent, info in agents.items():\n",
    "        for stats in info['runs_stats']:\n",
    "            prop_values = stats.to_dict()[parent_prop][prop]\n",
    "            seed = stats.agent_stats['agent_parameters']['agent_seed']\n",
    "            for i, v in enumerate(prop_values):\n",
    "                data.append([float(v), i, agent, seed])\n",
    "\n",
    "    return pd.DataFrame(data=data, columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aggregated_reward_df(agent_data, window_size=50):\n",
    "    data = []\n",
    "    columns = ['cumulative_reward', 'reward', 'timestep', 'seed', 'delta', 'agent_name', 'run_code']\n",
    "    for agent_name, info in agent_data.items():\n",
    "        for stats in info['runs_stats']:\n",
    "            seed = int(stats.agent_stats['agent_parameters']['agent_seed'])\n",
    "            if agent_name == 'LinUCB':\n",
    "                delta = float(stats.agent_stats['agent_parameters']['delta'])\n",
    "            else:\n",
    "                delta = None\n",
    "            run_code = stats.run_code\n",
    "            cum_reward = 0\n",
    "            cum_window = []\n",
    "            rew_window = []\n",
    "            for i, reward in enumerate(stats.execution_history_stats['reward']):\n",
    "                cum_reward += float(reward)\n",
    "                cum_window.append(cum_reward)\n",
    "                rew_window.append(float(reward))\n",
    "                if i % window_size == 0:\n",
    "                    cum_avg = sum(cum_window)/len(cum_window)\n",
    "                    rew_avg = sum(rew_window)/len(rew_window)\n",
    "                    time_step = i // window_size\n",
    "                    data.append([\n",
    "                        cum_avg,\n",
    "                        rew_avg,\n",
    "                        time_step,\n",
    "                        seed,\n",
    "                        delta,\n",
    "                        agent_name,\n",
    "                        run_code\n",
    "                    ])\n",
    "                    cum_window = []\n",
    "                    rew_window = []\n",
    "\n",
    "\n",
    "    return pd.DataFrame(data=data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_steps = (\n",
    "    {'label': '$\\lambda$ = 60', 'color': 'tab:olive', 'value': 0, 'linestyle': '--', 'linewidth': 2},\n",
    "    {'label': '$\\lambda$ = 600', 'color': 'tab:cyan', 'value': 1000, 'linestyle': '--', 'linewidth': 2},\n",
    "    {'label': '$\\lambda$ = 30', 'color': 'tab:pink', 'value': 2000, 'linestyle': '--', 'linewidth': 2}\n",
    ")\n",
    "\n",
    "def plot_assignments_data(df, sup_title, name, code, save_image=True,\n",
    "                          figsize=(24, 16), window_size=25, steps=default_steps,\n",
    "                          ytext_1=None, ytext_2=None,\n",
    "                          legend_1_x=None, legend_1_y=None, legend_1_loc='best',\n",
    "                          legend_2_x=None, legend_2_y=None, legend_2_loc='best'\n",
    "                         ):\n",
    "    fig, axs = plt.subplots(2, 1, figsize=figsize)\n",
    "    # fig.suptitle(sup_title, fontsize=18)\n",
    "    \n",
    "    def add_vlines(axes, text_y):\n",
    "        for step in steps:\n",
    "            step_value = step['value'] / window_size\n",
    "            axes.axvline(step_value, label=step['label'], c=step['color'],\n",
    "                         linestyle=step['linestyle'], linewidth=step['linewidth'])\n",
    "            axes.text(step_value + 0.3, text_y, step['label'], rotation=0, verticalalignment='baseline', fontsize=16)\n",
    "    \n",
    "    sns.lineplot(data=df, x=\"time_step\", y=\"reward\", hue=\"agent\", ax=axs[0])\n",
    "    # axs[0].set_title('Average reward per time window of {} time steps'.format(window_size))\n",
    "    axs[0].set_ylabel('Average reward')\n",
    "    axs[0].set_xlabel(f'Time window ({window_size} steps)')\n",
    "    if legend_1_x is not None and legend_1_y is not None:\n",
    "        axs[0].legend(bbox_to_anchor=(legend_1_x, legend_1_y),borderaxespad=0, loc=legend_1_loc)\n",
    "    else:\n",
    "        axs[0].legend(bbox_to_anchor=(1.01, 1),borderaxespad=0, loc=legend_1_loc)\n",
    "    min_v = df.reward.min()\n",
    "    max_v = df.reward.max()\n",
    "    step = ((min_v - max_v) // 5) * 2.5\n",
    "    if ytext_1 is not None:\n",
    "        step = ytext_1\n",
    "    \n",
    "    add_vlines(axs[0], step)\n",
    "\n",
    "    sns.lineplot(data=df, x=\"time_step\", y=\"cumulative_reward\", hue=\"agent\", ax=axs[1])\n",
    "    # axs[1].set_title('Cumulative reward every {} steps'.format(window_size))\n",
    "    axs[1].set_ylabel('Cumulative reward')\n",
    "    axs[1].set_xlabel(f'Time window ({window_size} steps)')\n",
    "    if legend_2_x is not None and legend_2_y is not None:\n",
    "        axs[1].legend(bbox_to_anchor=(legend_2_x, legend_2_y),borderaxespad=0, loc=legend_2_loc)\n",
    "    else:\n",
    "        axs[1].legend(bbox_to_anchor=(1.01, 1),borderaxespad=0, loc=legend_2_loc)\n",
    "    min_v = df.cumulative_reward.min()\n",
    "    max_v = df.cumulative_reward.max()\n",
    "    step = (min_v - max_v) // 5 * 3\n",
    "    if ytext_2 is not None:\n",
    "        step = ytext_2\n",
    "\n",
    "    add_vlines(axs[1], step)\n",
    "    \n",
    "    if save_image:\n",
    "        fig.savefig(f'{BASE_PATH}/{code}/evaluation-history.pdf', bbox_inches='tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_agents(df, names):\n",
    "    for agent_old, agent_new in names.items():\n",
    "        df.replace({'agent': agent_old}, agent_new, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waiting Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_FOLDER = 'eval-new-multi-waiting-time'\n",
    "agents = {\n",
    "    'LinUCB': {\n",
    "        'runs_names': [],\n",
    "        'runs_stats': []\n",
    "    },\n",
    "    'DoubleDQN': {\n",
    "        'runs_names': [],\n",
    "        'runs_stats': []\n",
    "    },\n",
    "    'Random': {\n",
    "        'runs_names': [],\n",
    "        'runs_stats': []\n",
    "    },\n",
    "    'LRU': {\n",
    "        'runs_names': [],\n",
    "        'runs_stats': []\n",
    "    }\n",
    "}\n",
    "agents_wt = load_agents_data(agents, handler, RESULT_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_FOLDER = 'new-baseline-waiting-time-multi-load'\n",
    "baselines = {\n",
    "    'E-PVM': {\n",
    "        'runs_names': [],\n",
    "        'runs_stats': []\n",
    "    }\n",
    "}\n",
    "baselines_wt = load_agents_data(baselines, handler, RESULT_FOLDER)\n",
    "for agent, data in baselines_wt.items():\n",
    "    agents_wt[agent] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards_df_wt = get_stats_dataframe(\n",
    "    agents_wt,\n",
    "    {\n",
    "        'label': 'total_reward',\n",
    "        'name': 'reward',\n",
    "        'aggregation': 'sum'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reward assignment history analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 25\n",
    "history_df_wt = get_assignment_history_df(agents_wt, window_size=window_size)     \n",
    "history_df_wt = rename_agents(history_df_wt, {'LinUCB': 'RLQ-LinUCB', 'DoubleDQN': 'RLQ-DoubleDQN', 'E-PVM': 'E-PVM'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_assignments_data(\n",
    "    history_df_wt, \n",
    "    'Waiting Time - Evaluation results with multi load',\n",
    "    'Waiting Time', \n",
    "    'waiting-time', \n",
    "    save_image=True,\n",
    "    figsize=(10, 22),\n",
    "    window_size=window_size,\n",
    "    ytext_1=-880,\n",
    "    ytext_2=-44000,\n",
    "    legend_1_x=0.45,\n",
    "    legend_1_y=0.42,\n",
    "    legend_2_x=0.45,\n",
    "    legend_2_y=0.42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_FOLDER = 'eval-new-multi-execution-time'\n",
    "agents = {\n",
    "    'LinUCB': {\n",
    "        'runs_names': [],\n",
    "        'runs_stats': []\n",
    "    },\n",
    "    'DoubleDQN': {\n",
    "        'runs_names': [],\n",
    "        'runs_stats': []\n",
    "    },\n",
    "    'Random': {\n",
    "        'runs_names': [],\n",
    "        'runs_stats': []\n",
    "    },\n",
    "    'LRU': {\n",
    "        'runs_names': [],\n",
    "        'runs_stats': []\n",
    "    }\n",
    "}\n",
    "agents_et = load_agents_data(agents, handler, RESULT_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_FOLDER = 'new-baseline-execution-time-multi-load'\n",
    "baselines = {\n",
    "    'E-PVM': {\n",
    "        'runs_names': [],\n",
    "        'runs_stats': []\n",
    "    }\n",
    "}\n",
    "baselines_et = load_agents_data(baselines, handler, RESULT_FOLDER)\n",
    "for agent, data in baselines_et.items():\n",
    "    agents_et[agent] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reward assignment history analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 25\n",
    "history_df_et = get_assignment_history_df(agents_et, window_size=window_size)  \n",
    "history_df_et = rename_agents(history_df_et, {'LinUCB': 'RLQ-LinUCB', 'DoubleDQN': 'RLQ-DoubleDQN', 'E-PVM': 'E-PVM'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_assignments_data(\n",
    "    history_df_et, \n",
    "    'Execution Time - Evaluation results with multi load',\n",
    "    'Execution Time', \n",
    "    'execution-time', \n",
    "    save_image=True,\n",
    "    figsize=(10, 22),\n",
    "    window_size=window_size,\n",
    "    ytext_1=-0.45,\n",
    "    ytext_2=-420,\n",
    "    legend_1_x=0.65,\n",
    "    legend_1_y=0.31,\n",
    "    legend_2_x=0.45,\n",
    "    legend_2_y=0.42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_FOLDER = 'eval-new-multi-execution-cost'\n",
    "agents = {\n",
    "    'LinUCB': {\n",
    "        'runs_names': [],\n",
    "        'runs_stats': []\n",
    "    },\n",
    "    'DoubleDQN': {\n",
    "        'runs_names': [],\n",
    "        'runs_stats': []\n",
    "    },\n",
    "    'Random': {\n",
    "        'runs_names': [],\n",
    "        'runs_stats': []\n",
    "    },\n",
    "    'LRU': {\n",
    "        'runs_names': [],\n",
    "        'runs_stats': []\n",
    "    }\n",
    "}\n",
    "agents_ec = load_agents_data(agents, handler, RESULT_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_FOLDER = 'new-baseline-execution-cost-multi-load'\n",
    "baselines = {\n",
    "    'E-PVM': {\n",
    "        'runs_names': [],\n",
    "        'runs_stats': []\n",
    "    }\n",
    "}\n",
    "baselines_ec = load_agents_data(baselines, handler, RESULT_FOLDER)\n",
    "for agent, data in baselines_ec.items():\n",
    "    agents_ec[agent] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards_df_ec = get_stats_dataframe(\n",
    "    agents_ec,\n",
    "    {\n",
    "        'label': 'total_reward',\n",
    "        'name': 'reward',\n",
    "        'aggregation': 'sum'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reward assignment history analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 25\n",
    "history_df_ec = get_assignment_history_df(agents_ec, window_size=window_size)  \n",
    "history_df_ec = rename_agents(history_df_ec, {'LinUCB': 'RLQ-LinUCB', 'DoubleDQN': 'RLQ-DoubleDQN', 'E-PVM': 'E-PVM'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_assignments_data(\n",
    "    history_df_ec, \n",
    "    'Execution Cost - Evaluation results with multi load',\n",
    "    'Execution Cost', \n",
    "    'execution-cost', \n",
    "    save_image=True,\n",
    "    figsize=(10, 22),\n",
    "    window_size=window_size,\n",
    "    ytext_1=-2.2,\n",
    "    ytext_2=-950,\n",
    "    legend_1_x=0.4,\n",
    "    legend_1_y=0.3,\n",
    "    legend_2_x=0.44,\n",
    "    legend_2_y=0.42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards_df_ec.groupby(['agent']).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df_wt = history_df_wt.assign(reward_function='Waiting Time')\n",
    "history_df_et = history_df_et.assign(reward_function='Execution Time')\n",
    "history_df_ec = history_df_ec.assign(reward_function='Execution Cost')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_df = pd.concat([history_df_wt, history_df_et, history_df_ec, history_df_make], ignore_index=True)\n",
    "combined_df = pd.concat([history_df_wt, history_df_et, history_df_ec], ignore_index=True)\n",
    "combined_df = rename_agents(combined_df, {'E-PVM': 'E-PVM'})\n",
    "combined_df['reward'] = combined_df['reward'] * -1\n",
    "combined_df['cumulative_reward'] = combined_df['cumulative_reward'] * -1\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.groupby(['agent', 'reward_function']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[combined_df.reward_function == 'Waiting Time'].reward.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\", font_scale=2.8)\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(40, 16))\n",
    "\n",
    "reward_functions = ['Execution Time', 'Execution Cost', 'Waiting Time']\n",
    "letters = ['(a)', '(b)', '(c)']\n",
    "n_agents = len(list(combined_df.groupby(['agent']).count().index)) \n",
    "\n",
    "\n",
    "default_steps = (\n",
    "    {'label': '$\\lambda$ = 60', 'color': 'tab:olive', 'value': 0, 'linestyle': '--', 'linewidth': 2},\n",
    "    {'label': '$\\lambda$ = 600', 'color': 'tab:cyan', 'value': 1000, 'linestyle': '--', 'linewidth': 2},\n",
    "    {'label': '$\\lambda$ = 30', 'color': 'tab:pink', 'value': 2000, 'linestyle': '--', 'linewidth': 2}\n",
    ")\n",
    "\n",
    "\n",
    "def add_vlines(axes, text_y):\n",
    "    for step in default_steps:\n",
    "        step_value = step['value'] / window_size\n",
    "        axes.axvline(step_value, label=step['label'], c=step['color'],\n",
    "                     linestyle=step['linestyle'], linewidth=step['linewidth'])\n",
    "        # axes.text(step_value + 0.3, text_y, step['label'], rotation=0, verticalalignment='baseline', fontsize=16)\n",
    "\n",
    "for i, rew_func in enumerate(reward_functions):\n",
    "    filterd_df = combined_df[combined_df.reward_function == rew_func]\n",
    "    sns.lineplot(data=filterd_df, x=\"time_step\", y=\"reward\", hue=\"agent\", ax=axs[0, i])\n",
    "    axs[0, i].set_title(f'{letters[i]} {rew_func}')\n",
    "    axs[0, i].set_xlabel('')\n",
    "    if i == 0:\n",
    "        axs[0, i].set_ylabel('Average metric value')\n",
    "    else:\n",
    "        axs[0, i].set_ylabel('')\n",
    "    axs[0, i].legend_.remove()\n",
    "    axs[0, i].set_xticks([])\n",
    "    \n",
    "    min_v = filterd_df.reward.min()\n",
    "    max_v = filterd_df.reward.max()\n",
    "    step = ((min_v - max_v) // 5) * 2.5\n",
    "\n",
    "    add_vlines(axs[0, i], step)\n",
    "    \n",
    "    sns.lineplot(data=filterd_df, x=\"time_step\", y=\"cumulative_reward\", hue=\"agent\", ax=axs[1, i])\n",
    "    # axs[1].set_title('Cumulative reward every {} steps'.format(window_size))\n",
    "    if i == 0:\n",
    "        axs[1, i].set_ylabel('Cumulative metric value')\n",
    "    else:\n",
    "        axs[1, i].set_ylabel('')\n",
    "    axs[1, i].set_xlabel(f'Time window ({window_size} steps)')\n",
    "    axs[1, i].legend_.remove()\n",
    "    \n",
    "    min_v = filterd_df.cumulative_reward.min()\n",
    "    max_v = filterd_df.cumulative_reward.max()\n",
    "    step = (min_v - max_v) // 5 * 3\n",
    "\n",
    "    add_vlines(axs[1, i], step)\n",
    "\n",
    "handles, labels = axs[0,0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 1.05),\n",
    "           ncol=n_agents + len(default_steps), frameon=False, fancybox=False)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "if not os.path.exists(f'{BASE_PATH}/all_rewards'):\n",
    "    os.mkdir(f'{BASE_PATH}/all_rewards')\n",
    "fig.savefig(f'{BASE_PATH}/all_rewards/evaluation-history-multi-load.pdf', bbox_inches='tight', dpi=plt.gcf().dpi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
